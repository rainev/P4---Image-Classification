
============================
File: packages/dashboard.proto
============================
syntax = "proto3";

package dashboard;

// ===============================
// Service Definition
// ===============================

service DashboardService {
  // Training app sends a stream of TrainingBatch messages during training.
  // Dashboard consumes them and returns a simple Ack when training is done.
  rpc StreamTrainingData(stream TrainingBatch) returns (Ack);

  // Optional health check / status RPC
  rpc Ping(PingRequest) returns (PingResponse);
}

// ===============================
// Messages
// ===============================

// One update from the training app for a training step
message TrainingBatch {
  // Parallel arrays: item i in each list corresponds to one image
  repeated bytes images = 1;         // encoded image bytes (PNG/JPEG)
  repeated string pred_labels = 2;   // model predictions as human-readable labels
  repeated string true_labels = 3;   // ground-truth labels

  float loss = 4;                    // loss for this batch/step
  int64 step = 5;                    // global training step/iteration
  int32 epoch = 6;                   // epoch index

  int32 batch_size = 7;              // actual batch size for this message
  int64 sent_timestamp_ms = 8;       // client send time (ms since epoch)
  int32 image_width = 9;             // image width
  int32 image_height = 10;           // image height
}

// Simple acknowledgement when stream ends
message Ack {
  bool ok = 1;
  string message = 2;
}

// Health check request
message PingRequest {
  string client_id = 1;              // ID of the training run
  int64 client_timestamp_ms = 2;     // time on client when ping was sent
}

// Health check response
message PingResponse {
  bool alive = 1;                    // whether dashboard is alive/ready
  string status = 2;                 // e.g. "OK", "NO_DATA", "BUSY"
  int64 server_timestamp_ms = 3;     // time on server when reply sent

  int32 frames_per_second = 4;       // current FPS measured by dashboard
  int32 queue_size = 5;              // how many TrainingBatches are waiting in queue
}-e 


============================
File: services/proto/dashboard_pb2.py
============================
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: dashboard.proto
# Protobuf Python Version: 4.25.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x0f\x64\x61shboard.proto\x12\tdashboard\"\xce\x01\n\rTrainingBatch\x12\x0e\n\x06images\x18\x01 \x03(\x0c\x12\x13\n\x0bpred_labels\x18\x02 \x03(\t\x12\x13\n\x0btrue_labels\x18\x03 \x03(\t\x12\x0c\n\x04loss\x18\x04 \x01(\x02\x12\x0c\n\x04step\x18\x05 \x01(\x03\x12\r\n\x05\x65poch\x18\x06 \x01(\x05\x12\x12\n\nbatch_size\x18\x07 \x01(\x05\x12\x19\n\x11sent_timestamp_ms\x18\x08 \x01(\x03\x12\x13\n\x0bimage_width\x18\t \x01(\x05\x12\x14\n\x0cimage_height\x18\n \x01(\x05\"\"\n\x03\x41\x63k\x12\n\n\x02ok\x18\x01 \x01(\x08\x12\x0f\n\x07message\x18\x02 \x01(\t\"=\n\x0bPingRequest\x12\x11\n\tclient_id\x18\x01 \x01(\t\x12\x1b\n\x13\x63lient_timestamp_ms\x18\x02 \x01(\x03\"y\n\x0cPingResponse\x12\r\n\x05\x61live\x18\x01 \x01(\x08\x12\x0e\n\x06status\x18\x02 \x01(\t\x12\x1b\n\x13server_timestamp_ms\x18\x03 \x01(\x03\x12\x19\n\x11\x66rames_per_second\x18\x04 \x01(\x05\x12\x12\n\nqueue_size\x18\x05 \x01(\x05\x32\x8d\x01\n\x10\x44\x61shboardService\x12@\n\x12StreamTrainingData\x12\x18.dashboard.TrainingBatch\x1a\x0e.dashboard.Ack(\x01\x12\x37\n\x04Ping\x12\x16.dashboard.PingRequest\x1a\x17.dashboard.PingResponseb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'dashboard_pb2', _globals)
if _descriptor._USE_C_DESCRIPTORS == False:
  DESCRIPTOR._options = None
  _globals['_TRAININGBATCH']._serialized_start=31
  _globals['_TRAININGBATCH']._serialized_end=237
  _globals['_ACK']._serialized_start=239
  _globals['_ACK']._serialized_end=273
  _globals['_PINGREQUEST']._serialized_start=275
  _globals['_PINGREQUEST']._serialized_end=336
  _globals['_PINGRESPONSE']._serialized_start=338
  _globals['_PINGRESPONSE']._serialized_end=459
  _globals['_DASHBOARDSERVICE']._serialized_start=462
  _globals['_DASHBOARDSERVICE']._serialized_end=603
# @@protoc_insertion_point(module_scope)
-e 


============================
File: services/proto/dashboard_pb2_grpc.py
============================
# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
import grpc

from services.proto import dashboard_pb2 as dashboard__pb2


class DashboardServiceStub(object):
    """===============================
    Service Definition
    ===============================

    """

    def __init__(self, channel):
        """Constructor.

        Args:
            channel: A grpc.Channel.
        """
        self.StreamTrainingData = channel.stream_unary(
                '/dashboard.DashboardService/StreamTrainingData',
                request_serializer=dashboard__pb2.TrainingBatch.SerializeToString,
                response_deserializer=dashboard__pb2.Ack.FromString,
                )
        self.Ping = channel.unary_unary(
                '/dashboard.DashboardService/Ping',
                request_serializer=dashboard__pb2.PingRequest.SerializeToString,
                response_deserializer=dashboard__pb2.PingResponse.FromString,
                )


class DashboardServiceServicer(object):
    """===============================
    Service Definition
    ===============================

    """

    def StreamTrainingData(self, request_iterator, context):
        """Training app sends a stream of TrainingBatch messages during training.
        Dashboard consumes them and returns a simple Ack when training is done.
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def Ping(self, request, context):
        """Optional health check / status RPC
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')


def add_DashboardServiceServicer_to_server(servicer, server):
    rpc_method_handlers = {
            'StreamTrainingData': grpc.stream_unary_rpc_method_handler(
                    servicer.StreamTrainingData,
                    request_deserializer=dashboard__pb2.TrainingBatch.FromString,
                    response_serializer=dashboard__pb2.Ack.SerializeToString,
            ),
            'Ping': grpc.unary_unary_rpc_method_handler(
                    servicer.Ping,
                    request_deserializer=dashboard__pb2.PingRequest.FromString,
                    response_serializer=dashboard__pb2.PingResponse.SerializeToString,
            ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
            'dashboard.DashboardService', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))


 # This class is part of an EXPERIMENTAL API.
class DashboardService(object):
    """===============================
    Service Definition
    ===============================

    """

    @staticmethod
    def StreamTrainingData(request_iterator,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.stream_unary(request_iterator, target, '/dashboard.DashboardService/StreamTrainingData',
            dashboard__pb2.TrainingBatch.SerializeToString,
            dashboard__pb2.Ack.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def Ping(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/dashboard.DashboardService/Ping',
            dashboard__pb2.PingRequest.SerializeToString,
            dashboard__pb2.PingResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
-e 


============================
File: services/dashboard/grpc_server.py
============================
# services/dashboard_app/grpc_server.py
from concurrent import futures
import time
import grpc

from services.proto import dashboard_pb2, dashboard_pb2_grpc


class DashboardService(dashboard_pb2_grpc.DashboardServiceServicer):
    def __init__(self, state_manager):
        self.state = state_manager

    def StreamTrainingData(self, request_iterator, context):
        """
        Receives a stream of TrainingBatch messages from the training app.
        For each batch, we update the shared state for the UI to consume.
        """
        try:
            for batch in request_iterator:
                self.state.update_from_batch(batch)
            return dashboard_pb2.Ack(ok=True, message="Training stream ended.")
        except grpc.RpcError as e:
            # You can log this and mention it in fault-tolerance discussion
            return dashboard_pb2.Ack(ok=False, message=f"RPC error: {e}")

    def Ping(self, request, context):
        """
        Health check RPC. Returns current FPS and queue size, plus server time.
        """
        fps, queue_size = self.state.get_status()
        now_ms = int(time.time() * 1000)
        return dashboard_pb2.PingResponse(
            alive=True,
            status="OK",
            server_timestamp_ms=now_ms,
            frames_per_second=int(fps),
            queue_size=queue_size,
        )


def serve_in_foreground(state_manager, port: int = 50051):
    """
    Starts the gRPC server and blocks. Intended to be called inside a background
    thread from main.py so the UI thread remains free.
    """
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=4))
    dashboard_pb2_grpc.add_DashboardServiceServicer_to_server(
        DashboardService(state_manager),
        server,
    )
    server.add_insecure_port(f"[::]:{port}")
    server.start()
    print(f"[Dashboard] gRPC server started on port {port}")
    server.wait_for_termination()-e 


============================
File: services/dashboard/state_manager.py
============================
# services/dashboard_app/state_manager.py
import threading


class StateManager:
    """
    Thread-safe shared state between the gRPC server (producer)
    and the Qt UI (consumer).
    """

    def __init__(self):
        self._lock = threading.Lock()
        self._latest_batch = None
        self._loss_history = []   # list of (step, loss)
        self._last_step = None
        self._fps = 0.0
        self._queue_size = 0      # simple indicator (we overwrite latest)

    def update_from_batch(self, batch):
        """
        Called by the gRPC server thread whenever a new TrainingBatch arrives.
        """
        with self._lock:
            self._latest_batch = batch
            # We only keep the latest batch, so queue_size is effectively 1.
            self._queue_size = 1

            # Track loss history per step
            if batch.step != self._last_step:
                self._loss_history.append((batch.step, batch.loss))
                self._last_step = batch.step

    def get_latest_for_ui(self):
        """
        Called by the UI thread every frame to read the latest data.
        """
        with self._lock:
            batch = self._latest_batch
            loss_history_copy = list(self._loss_history)
            queue_size = self._queue_size
        return batch, loss_history_copy, queue_size

    def set_fps(self, fps: float):
        with self._lock:
            self._fps = fps

    def get_status(self):
        """
        Returns (fps, queue_size) for Ping() RPC.
        """
        with self._lock:
            return self._fps, self._queue_size-e 


============================
File: services/dashboard/ui.py
============================
# services/dashboard_app/ui.py
import time

from PyQt6.QtCore import QTimer, Qt
from PyQt6.QtGui import QImage, QPixmap
from PyQt6.QtWidgets import (
    QWidget,
    QLabel,
    QGridLayout,
    QVBoxLayout,
    QHBoxLayout,
    QMainWindow,
)
import pyqtgraph as pg


class DashboardWindow(QMainWindow):
    def __init__(self, state_manager):
        super().__init__()
        self.state_manager = state_manager

        self.setWindowTitle("Image Classifier Dashboard")
        self.resize(1600, 900)

        # For FPS calculation
        self._last_frame_time = time.perf_counter()
        self._fps = 0.0

        # Track last rendered step to avoid redundant redraws
        self._last_step_rendered = None

        # Build UI layout
        self._build_ui()

        # Timer for ~60 FPS render loop (16 ms)
        self._timer = QTimer(self)
        self._timer.timeout.connect(self._on_frame)
        self._timer.start(16)

    def _build_ui(self):
        central = QWidget()
        main_layout = QVBoxLayout()
        top_layout = QHBoxLayout()

        # 4x4 image grid
        self.image_labels = []
        image_grid_widget = QWidget()
        image_grid_layout = QGridLayout()
        for r in range(4):
            for c in range(4):
                lbl = QLabel()
                lbl.setFixedSize(150, 150)
                lbl.setStyleSheet(
                    "background-color: #222; border: 1px solid #555; color: #888;"
                )
                lbl.setAlignment(Qt.AlignmentFlag.AlignCenter)
                lbl.setText("No\nImage")
                image_grid_layout.addWidget(lbl, r, c)
                self.image_labels.append(lbl)
        image_grid_widget.setLayout(image_grid_layout)

        # 4x4 prediction/ground-truth label grid
        self.text_labels = []
        text_grid_widget = QWidget()
        text_grid_layout = QGridLayout()
        for r in range(4):
            for c in range(4):
                lbl = QLabel()
                lbl.setFixedSize(150, 60)
                lbl.setStyleSheet(
                    "background-color: #222; border: 1px solid #555; color: white;"
                )
                lbl.setAlignment(Qt.AlignmentFlag.AlignCenter)
                lbl.setText("— / —")
                text_grid_layout.addWidget(lbl, r, c)
                self.text_labels.append(lbl)
        text_grid_widget.setLayout(text_grid_layout)

        top_layout.addWidget(image_grid_widget)
        top_layout.addWidget(text_grid_widget)

        # Loss plot using pyqtgraph
        self.loss_plot_widget = pg.PlotWidget()
        self.loss_plot_widget.setBackground("k")
        self.loss_plot_widget.setLabel("left", "Loss")
        self.loss_plot_widget.setLabel("bottom", "Step")
        self.loss_curve = self.loss_plot_widget.plot([], [], pen="y")

        # FPS + latency labels
        status_layout = QHBoxLayout()
        self.fps_label = QLabel("FPS: 0.0")
        self.fps_label.setStyleSheet("color: white;")
        self.latency_label = QLabel("Latency: — ms")
        self.latency_label.setStyleSheet("color: white;")

        status_layout.addWidget(self.fps_label)
        status_layout.addWidget(self.latency_label)
        status_widget = QWidget()
        status_widget.setLayout(status_layout)

        main_layout.addLayout(top_layout)
        main_layout.addWidget(self.loss_plot_widget)
        main_layout.addWidget(status_widget)

        central.setStyleSheet("background-color: #111; color: white;")
        central.setLayout(main_layout)
        self.setCentralWidget(central)

    def _on_frame(self):
        # --- FPS calculation ---
        now = time.perf_counter()
        dt = now - self._last_frame_time
        if dt > 0:
            # Exponential moving average for smoother FPS
            instant_fps = 1.0 / dt
            self._fps = (self._fps * 0.9) + (0.1 * instant_fps)
        self._last_frame_time = now
        self.fps_label.setText(f"FPS: {self._fps:5.1f}")

        # Update shared FPS so Ping() can report it
        self.state_manager.set_fps(self._fps)

        # --- Get latest batch from state manager ---
        batch, loss_history, queue_size = self.state_manager.get_latest_for_ui()
        if batch is None:
            return

        # Only re-render if new step arrived
        if batch.step == self._last_step_rendered:
            return
        self._last_step_rendered = batch.step

        # --- Update images & labels (4x4 tiles, i.e., 16 maximum) ---
        num_samples = min(16, len(batch.images))
        for i in range(16):
            if i < num_samples:
                img_bytes = batch.images[i]

                pred = (
                    batch.pred_labels[i]
                    if i < len(batch.pred_labels)
                    else "?"
                )
                true = (
                    batch.true_labels[i]
                    if i < len(batch.true_labels)
                    else "?"
                )

                # Decode bytes to pixmap
                pixmap = self._bytes_to_pixmap(img_bytes)
                if pixmap is not None:
                    self.image_labels[i].setPixmap(
                        pixmap.scaled(
                            self.image_labels[i].width(),
                            self.image_labels[i].height(),
                            Qt.AspectRatioMode.KeepAspectRatio,
                            Qt.TransformationMode.SmoothTransformation,
                        )
                    )
                    self.image_labels[i].setText("")  # clear placeholder text
                else:
                    self.image_labels[i].setPixmap(QPixmap())
                    self.image_labels[i].setText("Bad\nImage")

                # Color-code pred/true label
                correct = (pred == true)
                color = "#2ecc71" if correct else "#e74c3c"  # green/red
                self.text_labels[i].setStyleSheet(
                    f"background-color: #222; border: 1px solid #555; color: {color};"
                )
                self.text_labels[i].setText(f"{pred} / {true}")
            else:
                # Empty tiles
                self.image_labels[i].setPixmap(QPixmap())
                self.image_labels[i].setText("No\nImage")
                self.text_labels[i].setStyleSheet(
                    "background-color: #222; border: 1px solid #555; color: white;"
                )
                self.text_labels[i].setText("— / —")

        # --- Update loss plot ---
        if loss_history:
            steps, losses = zip(*loss_history)
            self.loss_curve.setData(steps, losses)

        # --- Latency (dashboard now - batch.sent_timestamp_ms) ---
        now_ms = int(time.time() * 1000)
        latency_ms = now_ms - batch.sent_timestamp_ms
        self.latency_label.setText(f"Latency: {latency_ms} ms")

    def _bytes_to_pixmap(self, img_bytes):
        if not img_bytes:
            return None
        qimg = QImage.fromData(img_bytes)
        if qimg.isNull():
            return None
        return QPixmap.fromImage(qimg)-e 


============================
File: services/dashboard/main.py
============================
# services/dashboard_app/main.py
import sys
import threading

from PyQt6.QtWidgets import QApplication

from services.dashboard.state_manager import StateManager
from services.dashboard.ui import DashboardWindow
from services.dashboard.grpc_server import serve_in_foreground


def _start_grpc_server(state_manager):
    # Blocking call; will run in a background thread
    serve_in_foreground(state_manager, port=50051)


def main():
    # Shared state between gRPC server and UI
    state_manager = StateManager()

    # Start gRPC server in a background thread
    server_thread = threading.Thread(
        target=_start_grpc_server,
        args=(state_manager,),
        daemon=True,
    )
    server_thread.start()

    # Start Qt application
    app = QApplication(sys.argv)
    window = DashboardWindow(state_manager)
    window.show()

    sys.exit(app.exec())


if __name__ == "__main__":
    main()-e 


============================
File: training/data_loader.py
============================
# training/data_loader.py

import torch
import torchvision
import torchvision.transforms as transforms


def get_mnist_loader(
    data_dir: str = "./data",
    batch_size: int = 16,
    num_workers: int = 2,
):
    """
    Returns a DataLoader for the MNIST training set.
    Downloads the dataset into data_dir if not yet present.
    """
    transform = transforms.Compose([
        transforms.ToTensor(),  # => float tensor [0,1], shape (1, 28, 28)
    ])

    train_dataset = torchvision.datasets.MNIST(
        root=data_dir,
        train=True,
        download=True,
        transform=transform,
    )

    train_loader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
    )

    return train_loader-e 


============================
File: training/model.py
============================
# training/model.py

import torch
import torch.nn as nn
import torch.nn.functional as F


class MnistCNN(nn.Module):
    """
    Simple convolutional neural network for MNIST (28x28 grayscale).
    """

    def __init__(self):
        super().__init__()
        # Input: (1, 28, 28)
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)   # -> (32, 28, 28)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # -> (64, 28, 28)
        self.pool = nn.MaxPool2d(2, 2)                            # -> (64, 14, 14)

        self.fc1 = nn.Linear(64 * 14 * 14, 128)
        self.fc2 = nn.Linear(128, 10)  # 10 digit classes (0–9)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        x = x.view(x.size(0), -1)  # flatten
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x-e 


============================
File: training/train.py
============================
# training/train.py

import io
import time

import grpc
import torch
import torch.nn as nn
import torch.optim as optim
from PIL import Image

from training.model import MnistCNN
from training.data_loader import get_mnist_loader
from services.proto import dashboard_pb2, dashboard_pb2_grpc


def encode_image_tensor(image_tensor):
    """
    Convert a single MNIST tensor (1, 28, 28) to PNG bytes.
    """
    img = image_tensor.squeeze().cpu().numpy() * 255.0  # [0,255]
    img = Image.fromarray(img.astype("uint8"), mode="L")  # grayscale

    buf = io.BytesIO()
    img.save(buf, format="PNG")
    return buf.getvalue()


def training_stream(model, train_loader, device, max_steps=400):
    """
    Generator used as the request iterator for StreamTrainingData.
    Does real training and yields a TrainingBatch per step.
    """
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-3)

    global_step = 0
    epoch_idx = 0
    model.train()

    for epoch in range(1, 1000):  # big number; we break via max_steps
        epoch_idx = epoch
        for batch_idx, (images, labels) in enumerate(train_loader):
            global_step += 1

            images = images.to(device)   # (B, 1, 28, 28)
            labels = labels.to(device)   # (B,)

            # ----- forward + backward + optimize -----
            optimizer.zero_grad()
            logits = model(images)
            loss = criterion(logits, labels)
            loss.backward()
            optimizer.step()

            # ----- prepare data for dashboard -----
            probs = torch.softmax(logits, dim=1)
            preds = torch.argmax(probs, dim=1)  # (B,)

            batch_size = images.size(0)
            num_samples = min(16, batch_size)   # 4x4 grid

            image_bytes_list = []
            pred_labels = []
            true_labels = []

            for i in range(num_samples):
                image_bytes_list.append(encode_image_tensor(images[i]))
                pred_labels.append(str(int(preds[i].cpu().item())))
                true_labels.append(str(int(labels[i].cpu().item())))

            yield dashboard_pb2.TrainingBatch(
                images=image_bytes_list,
                pred_labels=pred_labels,
                true_labels=true_labels,
                loss=float(loss.item()),
                step=global_step,
                epoch=epoch_idx,
                batch_size=num_samples,
                sent_timestamp_ms=int(time.time() * 1000),
                image_width=28,
                image_height=28,
            )

            if global_step >= max_steps:
                return  # stop generator after some steps to keep demo short


def main():
    # ----- gRPC channel & stub -----
    channel = grpc.insecure_channel("localhost:50051")
    stub = dashboard_pb2_grpc.DashboardServiceStub(channel)

    # ----- device & model -----
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = MnistCNN().to(device)

    # ----- data loader -----
    train_loader = get_mnist_loader(
        data_dir="./data",
        batch_size=16,
        num_workers=2,
    )

    # ----- start streaming training data -----
    print("▶ Starting CNN training and streaming to dashboard...")
    request_iter = training_stream(model, train_loader, device, max_steps=400)
    ack = stub.StreamTrainingData(request_iter)
    print("✔ Dashboard Ack:", ack.ok, ack.message)


if __name__ == "__main__":
    main()-e 


